Things to try:

- generate text
- generate text from examples given in the prompt ittself (?)
- suggest improvements to existing text
- change style of existing text (?)
- summarize text (perhaps down to only a few words)

[The surprising ease and effectiveness of AI in a loop](https://interconnected.org/home/2023/03/16/singularity)

[the dreaded first steps](https://twitter.com/thorstenball/status/1637064266095239168)

[Using GPT-4 to measure the passage of time in fiction](https://tedunderwood.com/2023/03/19/using-gpt-4-to-measure-the-passage-of-time-in-fiction/)

[ChatGPT is aware of today's date](https://ai.stackexchange.com/questions/39686/chatgpt-is-aware-of-todays-date)

> For ChatGPT 3, the current date is inserted into a long pre-prompt, along
> with instructions like "this is a conversation between an AI chatbot and a
> human" plus "be nice" and "be truthful", which are part of the attempts to
> frame the next-word-predicting engine at the core of ChatGPT as a chatbot.
> OpenAI confirm this approach in their general GPT documentation.

> Inherently, the core of ChatGPT - the GPT large language model - is not a
> chatbot. It has some resemblance conceptually to an image inpainting system â€”
> it predicts text that is likely, given preceding text.

[ChatGPT plugins](https://twitter.com/OpenAI/status/1638952876281335813). [hn](https://news.ycombinator.com/item?id=35277677). [comment](https://hachyderm.io/@mitchellh/110073950210671765). [lock-in](https://twitter.com/rickasaurus/status/1638572469282918400)

[talking to docs](https://twitter.com/dan_abramov/status/1638674605635239938)

>  i was wondering how much i am writing for humans and how much for the model

[The whole thing is parasitic on a substrate of solid technical writing](https://twitter.com/kevinbaker/status/1638974920074960896)

> In the long term, I think this is going to reshape technical writing and code documenting practices. People are going to write targeting LLMs and not just users.

[q: how do I use TLS here?](https://www.reddit.com/r/haskell/comments/11z50ks/comment/jdd5qcs/)

[glad I never learned X](https://twitter.com/dan_abramov/status/1639253192926978050)

[increasingly absurd](https://twitter.com/birchlse/status/1639258703961415680)

[non-native speakers](https://twitter.com/KrebsVerena/status/1638965122390450176)

[for learning](https://twitter.com/simonw/status/1639707628778692608)

["It's fine not to provide direct answers"](https://twitter.com/bgavran3/status/1639326236487843855)

[an explanation](https://news.ycombinator.com/item?id=35312969)

> The pre-trained model is stage 1 - it has seen everything, but it is wild. If you ask it "What is the capital of US?" it will reply "What is the capital of Canada?"...

> Stage 2 is task solving practice. We use 1000-2000 supervised datasets, formatted as prompt-input-output texts. They could be anything: translation, sentiment classification, question answering, etc. We also include prompt-code pairs. This teaches the model to solve tasks (it "hires" this ability from the model). Apparently training on code is essential, without it the model doesn't develop reasoning abilities.

> But still the model is not well behaved, it doesn't answer in a way we like. So in stage 3 it goes to human preference tuning (RLHF). This is based on human preferences between pairs of LLM answers. After RLHF it learns to behave and to abstain from certain topics.

> You need stage 1 for general knowledge, stage 2 for learning to execute prompts, stage 3 to make it behave.


